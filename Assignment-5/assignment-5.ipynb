{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ConvolutionalNeuralNetwork:\n",
    "    def __init__(self, input_shape, filter_size, num_filters):\n",
    "        # Initialize CNN parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) * 0.1  # Initialize filters with small values\n",
    "        self.biases = np.zeros(num_filters)  # Biases initialized to zero\n",
    "        self.lambda_reg = 0.01  # L2 regularization parameter\n",
    "        self.learning_rate = 0.01  # Learning rate\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        # X: Input data with shape (m, h, w), where m = number of samples, h = height, w = width\n",
    "        m, h, w = X.shape\n",
    "        num_filters, filter_size, _ = self.filters.shape  # num_filters = number of filters\n",
    "        h_out = h - filter_size + 1  # Output height after convolution\n",
    "        w_out = w - filter_size + 1  # Output width after convolution\n",
    "\n",
    "        Z = np.zeros((m, num_filters, h_out, w_out))  # Initialize the output of the convolution (activation map)\n",
    "\n",
    "        # Perform convolution with ReLU activation\n",
    "        for i in range(m):\n",
    "            for fi in range(num_filters):\n",
    "                for hi in range(h_out):\n",
    "                    for wi in range(w_out):\n",
    "                        # Perform the convolution operation (filter * image region + bias)\n",
    "                        Z[i, fi, hi, wi] = np.sum(X[i, hi:hi+filter_size, wi:wi+filter_size] * self.filters[fi]) + self.biases[fi]\n",
    "        return np.maximum(0, Z)  # Apply ReLU activation\n",
    "\n",
    "    def backward_prop(self, X, dZ):\n",
    "        m, h, w = X.shape\n",
    "        num_filters, filter_size, _ = self.filters.shape\n",
    "        dW = np.zeros_like(self.filters)\n",
    "        db = np.zeros_like(self.biases)\n",
    "\n",
    "        # Compute gradients for weights (filters) and biases\n",
    "        for i in range(m):\n",
    "            for fi in range(num_filters):\n",
    "                for hi in range(dZ.shape[2]):\n",
    "                    for wi in range(dZ.shape[3]):\n",
    "                        # Compute the gradients for each filter and bias\n",
    "                        dW[fi] += X[i, hi:hi+filter_size, wi:wi+filter_size] * dZ[i, fi, hi, wi]\n",
    "                        db[fi] += dZ[i, fi, hi, wi]\n",
    "\n",
    "        # L2 regularization gradient for filters\n",
    "        dW += self.lambda_reg * self.filters\n",
    "        return {'dW': dW / m, 'db': db / m}\n",
    "\n",
    "    def optimize(self, X, Y, num_iterations=1000):\n",
    "        costs = []\n",
    "        v_W = np.zeros_like(self.filters)  # Initialize momentum for filters\n",
    "        v_b = np.zeros_like(self.biases)  # Initialize momentum for biases\n",
    "        beta = 0.9  # Momentum parameter\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            # Forward propagation\n",
    "            Z = self.forward_prop(X)\n",
    "\n",
    "            # Calculate the cost (Mean Squared Error + L2 regularization)\n",
    "            cost = np.mean((Z - Y) ** 2) + (self.lambda_reg / 2) * np.sum(self.filters ** 2)\n",
    "            costs.append(cost)\n",
    "\n",
    "            # Backward propagation\n",
    "            dZ = 2 * (Z - Y)  # Derivative of MSE loss\n",
    "            grads = self.backward_prop(X, dZ)\n",
    "\n",
    "            # Update filters and biases with momentum\n",
    "            v_W = beta * v_W + (1 - beta) * grads['dW']\n",
    "            v_b = beta * v_b + (1 - beta) * grads['db']\n",
    "\n",
    "            self.filters -= self.learning_rate * v_W\n",
    "            self.biases -= self.learning_rate * v_b\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Cost after iteration {i}: {cost}\")\n",
    "\n",
    "        return costs\n",
    "\n",
    "# Test the implementation\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random input data: 5 samples of 14x14 images\n",
    "X = np.random.randn(5, 14, 14)\n",
    "\n",
    "# Generate random output data (target): assuming 12x12 output after convolution with a 3x3 receptive field\n",
    "# The target shape should match the output size of the convolution.\n",
    "Y = np.random.randn(5, 12, 12)  # Updated the target shape to match the expected output\n",
    "\n",
    "# Initialize the CNN with input shape (14, 14), filter size 3, and 5 filters\n",
    "cnn = ConvolutionalNeuralNetwork(input_shape=(14, 14), filter_size=3, num_filters=5)\n",
    "\n",
    "# Train the CNN\n",
    "print(\"Training the CNN...\")\n",
    "costs = cnn.optimize(X, Y, num_iterations=1000)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.plot(costs)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# https://chatgpt.com/share/68178187-d980-8009-9e32-b0f7685dc6ff"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
